{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eedec120",
   "metadata": {},
   "source": [
    "# Training and deploying a tabular model using Vertex custom training job - Part 1\n",
    "\n",
    "![Training pipeline](../images/custom-tabular.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f265128e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-08-05 23:35:30.343972: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from google.cloud import aiplatform as vertex_ai\n",
    "from google.cloud.aiplatform_v1beta1 import types\n",
    "from google.cloud.aiplatform import hyperparameter_tuning as hpt\n",
    "\n",
    "from google.cloud.aiplatform.utils import JobClientWithOverride"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbac738",
   "metadata": {},
   "source": [
    "## Configure GCP settings\n",
    "\n",
    "*Before running the notebook make sure to follow the repo's README file to install the pre-requisites.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dbee1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT = 'jk-mlops-dev'\n",
    "REGION = 'us-central1'\n",
    "\n",
    "STAGING_BUCKET = 'gs://jk-vertex-us-central1'\n",
    "\n",
    "#VERTEX_SA = f'vertex-sa@{PROJECT}.iam.gserviceaccount.com'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "779d15e0",
   "metadata": {},
   "source": [
    "### Initialize Vertex AI SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46110e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertex_ai.init(\n",
    "    project=PROJECT,\n",
    "    location=REGION,\n",
    "    staging_bucket=STAGING_BUCKET\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9c239c",
   "metadata": {},
   "source": [
    "### Prepare a training script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f5a536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT_FOLDER = 'trainer'\n",
    "if tf.io.gfile.exists(SCRIPT_FOLDER):\n",
    "    tf.io.gfile.rmtree(SCRIPT_FOLDER)\n",
    "tf.io.gfile.mkdir(SCRIPT_FOLDER)\n",
    "file_path = os.path.join(SCRIPT_FOLDER, 'train.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3b71cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing trainer/train.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {file_path}\n",
    "\n",
    "\n",
    "# Copyright 2021 Google Inc. All Rights Reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#            http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "\n",
    "import argparse\n",
    "import json\n",
    "import os\n",
    "import logging\n",
    "import time\n",
    "\n",
    "\n",
    "def get_args():\n",
    "    \"\"\"Defines and parse commandline arguments.\"\"\"\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\n",
    "        \"--output_path\",\n",
    "        default=\"/tmp\",\n",
    "        type=str,\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        \"--input_path\",\n",
    "        default=\"/tmp\",\n",
    "        type=str,\n",
    "    )\n",
    "\n",
    "    return parser.parse_args()\n",
    "\n",
    "def main():\n",
    "    args = get_args()\n",
    "    \n",
    "\n",
    "    logging.info('****Entering****')\n",
    "\n",
    "    print(os.listdir(args.input_path))\n",
    "    \n",
    "    logging.info('**** Exiting ****')\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    logging.getLogger().setLevel(logging.INFO)\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1caaf88",
   "metadata": {},
   "source": [
    "### Configure and submit a Vertex job using a custom container"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02161bb9",
   "metadata": {},
   "source": [
    "#### Create a docker file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb7cf6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BASE_IMAGE = 'us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-4:latest'\n",
    "#BASE_IMAGE = 'gcr.io/deeplearning-platform-release/tf2-gpu.2-4'\n",
    "BASE_IMAGE = 'nvcr.io/nvidia/merlin/merlin-training:0.5.3'\n",
    "\n",
    "TRAIN_IMAGE = f'gcr.io/{PROJECT}/merlin-train'\n",
    "\n",
    "dockerfile = f'''\n",
    "FROM {BASE_IMAGE}\n",
    "\n",
    "WORKDIR /trainer\n",
    "\n",
    "# Copies the trainer code to the docker image.\n",
    "COPY train.py .\n",
    "\n",
    "'''\n",
    "\n",
    "with open(os.path.join(SCRIPT_FOLDER, 'Dockerfile'), 'w') as f:\n",
    "    f.write(dockerfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f252d37",
   "metadata": {},
   "source": [
    "#### Build a container image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cf8c4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  4.096kB\n",
      "Step 1/3 : FROM nvcr.io/nvidia/merlin/merlin-training:0.5.3\n",
      " ---> 332a8cffc9df\n",
      "Step 2/3 : WORKDIR /trainer\n",
      " ---> Using cache\n",
      " ---> e6e49164504a\n",
      "Step 3/3 : COPY train.py .\n",
      " ---> Using cache\n",
      " ---> 944773da3e81\n",
      "Successfully built 944773da3e81\n",
      "Successfully tagged gcr.io/jk-mlops-dev/merlin-train:latest\n"
     ]
    }
   ],
   "source": [
    "! docker build -t {TRAIN_IMAGE} {SCRIPT_FOLDER}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbe0d638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using default tag: latest\n",
      "The push refers to repository [gcr.io/jk-mlops-dev/merlin-train]\n",
      "\n",
      "\u001b[1Bb8ac654e: Preparing \n",
      "\u001b[1B2e09c4ff: Preparing \n",
      "\u001b[1B714d2463: Preparing \n",
      "\u001b[1Bd2ff5b33: Preparing \n",
      "\u001b[1B37647ed0: Preparing \n",
      "\u001b[1B9f4cda5f: Preparing \n",
      "\u001b[1B21185477: Preparing \n",
      "\u001b[1Bb702c731: Preparing \n",
      "\u001b[1B976c398b: Preparing \n",
      "\u001b[1Bf82b8797: Preparing \n",
      "\u001b[1Bb5e2597b: Preparing \n",
      "\u001b[1B7dc1f6bf: Preparing \n",
      "\u001b[1B777553e2: Preparing \n",
      "\u001b[1B45ef7765: Preparing \n",
      "\u001b[1Bf02461c8: Preparing \n",
      "\u001b[1B49407eae: Preparing \n",
      "\u001b[1Bb75a89f5: Preparing \n",
      "\u001b[1B814e7f5b: Preparing \n",
      "\u001b[1B61fe548e: Preparing \n",
      "\u001b[1Bdac4ffdd: Preparing \n",
      "\u001b[1B218e5cc3: Preparing \n",
      "\u001b[1B668c53f6: Preparing \n",
      "\u001b[1B5d313a81: Preparing \n",
      "\u001b[1B010e7779: Preparing \n",
      "\u001b[1Bc68e5aca: Preparing \n",
      "\u001b[1B71f76135: Preparing \n",
      "\u001b[1Bfb51e15b: Preparing \n",
      "\u001b[1B4afa0df1: Preparing \n",
      "\u001b[1B9161954b: Preparing \n",
      "\u001b[23B702c731: Waiting g \n",
      "\u001b[1B367789f5: Preparing \n",
      "\u001b[1Ba0c42d3d: Preparing \n",
      "\u001b[25B76c398b: Waiting g \n",
      "\u001b[1B303ebf75: Preparing \n",
      "\u001b[1Bbafdc7ee: Layer already exists \u001b[33A\u001b[2K\u001b[30A\u001b[2K\u001b[27A\u001b[2K\u001b[24A\u001b[2K\u001b[21A\u001b[2K\u001b[18A\u001b[2K\u001b[15A\u001b[2K\u001b[11A\u001b[2K\u001b[9A\u001b[2K\u001b[6A\u001b[2K\u001b[3A\u001b[2K\u001b[1A\u001b[2Klatest: digest: sha256:3e9c9e83bb0d043724b60f3f6ebf5772bd4250b25b9dd92d4ba0f0e78f2b2d85 size: 7682\n"
     ]
    }
   ],
   "source": [
    "! docker push {TRAIN_IMAGE}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d43a109",
   "metadata": {},
   "source": [
    "#### Prepare worker pool specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d3f0df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'machine_spec': {'machine_type': 'n1-standard-4', 'accelerator_type': 'NVIDIA_TESLA_T4', 'accelerator_count': 1}, 'replica_count': 1, 'container_spec': {'image_uri': 'gcr.io/jk-mlops-dev/merlin-train', 'command': ['python', 'train.py'], 'args': ['--input_path=/gcs//jk-vertex-us-central1']}}]\n"
     ]
    }
   ],
   "source": [
    "job_name = 'MERLIN_CONTAINER_TEST_{}'.format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "base_output_dir = '{}/jobs/{}/test.txt'.format(STAGING_BUCKET, job_name)\n",
    "input_path = '/gcs/{}'.format(STAGING_BUCKET[4:])\n",
    "\n",
    "worker_pool_specs =  [\n",
    "    {\n",
    "        \"machine_spec\": {\n",
    "            \"machine_type\": \"n1-standard-4\",\n",
    "            \"accelerator_type\": \"NVIDIA_TESLA_T4\",\n",
    "            \"accelerator_count\": 1,\n",
    "        },\n",
    "        \"replica_count\": 1,\n",
    "        \"container_spec\": {\n",
    "            \"image_uri\": TRAIN_IMAGE,\n",
    "            \"command\": [\"python\", \"train.py\",],\n",
    "            \"args\": [             \n",
    "                '--input_path=' + input_path, \n",
    "            ],\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "print(worker_pool_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c90836",
   "metadata": {},
   "source": [
    "#### Submit and monitor the job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d613d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.jobs:Creating CustomJob\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob created. Resource name: projects/895222332033/locations/us-central1/customJobs/8556746933027209216\n",
      "INFO:google.cloud.aiplatform.jobs:To use this CustomJob in another session:\n",
      "INFO:google.cloud.aiplatform.jobs:custom_job = aiplatform.CustomJob.get('projects/895222332033/locations/us-central1/customJobs/8556746933027209216')\n",
      "INFO:google.cloud.aiplatform.jobs:View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/8556746933027209216?project=895222332033\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/8556746933027209216 current state:\n",
      "JobState.JOB_STATE_QUEUED\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/8556746933027209216 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/8556746933027209216 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/8556746933027209216 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/8556746933027209216 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/8556746933027209216 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/8556746933027209216 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/8556746933027209216 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob run completed. Resource name: projects/895222332033/locations/us-central1/customJobs/8556746933027209216\n"
     ]
    }
   ],
   "source": [
    "job = vertex_ai.CustomJob(\n",
    "    display_name=job_name,\n",
    "    worker_pool_specs=worker_pool_specs,\n",
    "    staging_bucket=base_output_dir\n",
    ")\n",
    "\n",
    "job.run(sync=False, \n",
    "#        service_account=VERTEX_SA,\n",
    "#        tensorboard=TENSORBOARD\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be150eb1",
   "metadata": {},
   "source": [
    "## Configure and submit a Vertex job using a GAPIC API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e28b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud.aiplatform.gapic import \\\n",
    "    JobServiceClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a425fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_name = 'GAPIC_CUSTOM_CONTAINER_{}'.format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "\n",
    "custom_job_spec = {\n",
    "    'display_name': job_name,\n",
    "    'job_spec': {\n",
    "        'worker_pool_specs': worker_pool_specs\n",
    "    }\n",
    "}\n",
    "\n",
    "print(custom_job_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9a7328",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_ENDPOINT = f'{REGION}-aiplatform.googleapis.com'\n",
    "\n",
    "options = dict(api_endpoint=API_ENDPOINT)\n",
    "client = JobServiceClient(client_options=options)\n",
    "\n",
    "parent = f\"projects/{PROJECT}/locations/{REGION}\"\n",
    "\n",
    "response = client.create_custom_job(\n",
    "    parent=parent, custom_job=custom_job_spec\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbbe7ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69083c37",
   "metadata": {},
   "source": [
    "### Configure and submit a Vertex job using `aiplatform.CustomJob.from_local_script`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "c73dede5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:google.cloud.aiplatform.utils.source_utils:Training script copied to:\n",
      "gs://jk-vertex-us-central1/jobs/CUSTOM_SCRIPT_GPU_GPU20210720_213359/aiplatform-2021-07-20-21:34:00.095-aiplatform_custom_trainer_script-0.1.tar.gz.\n",
      "INFO:google.cloud.aiplatform.jobs:Creating CustomJob\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob created. Resource name: projects/895222332033/locations/us-central1/customJobs/6593538135307583488\n",
      "INFO:google.cloud.aiplatform.jobs:To use this CustomJob in another session:\n",
      "INFO:google.cloud.aiplatform.jobs:custom_job = aiplatform.CustomJob.get('projects/895222332033/locations/us-central1/customJobs/6593538135307583488')\n",
      "INFO:google.cloud.aiplatform.jobs:View Custom Job:\n",
      "https://console.cloud.google.com/ai/platform/locations/us-central1/training/6593538135307583488?project=895222332033\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/6593538135307583488 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/6593538135307583488 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/6593538135307583488 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/6593538135307583488 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/7588411440491397120 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/1427909362713624576 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/8829575350297034752 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/5449623829955477504 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/6593538135307583488 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/3155039819810209792 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/1427909362713624576 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob run completed. Resource name: projects/895222332033/locations/us-central1/customJobs/1427909362713624576\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/7588411440491397120 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/6593538135307583488 current state:\n",
      "JobState.JOB_STATE_PENDING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/8829575350297034752 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/5449623829955477504 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/8829575350297034752 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob run completed. Resource name: projects/895222332033/locations/us-central1/customJobs/8829575350297034752\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/3155039819810209792 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/7588411440491397120 current state:\n",
      "JobState.JOB_STATE_RUNNING\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/3155039819810209792 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob run completed. Resource name: projects/895222332033/locations/us-central1/customJobs/3155039819810209792\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob projects/895222332033/locations/us-central1/customJobs/5449623829955477504 current state:\n",
      "JobState.JOB_STATE_SUCCEEDED\n",
      "INFO:google.cloud.aiplatform.jobs:CustomJob run completed. Resource name: projects/895222332033/locations/us-central1/customJobs/5449623829955477504\n"
     ]
    }
   ],
   "source": [
    "job_name = 'CUSTOM_SCRIPT_GPU_GPU{}'.format(time.strftime(\"%Y%m%d_%H%M%S\"))\n",
    "base_output_dir = '{}/jobs/{}'.format(STAGING_BUCKET, job_name)\n",
    "output_path = f'{base_output_dir}/test.txt'\n",
    "\n",
    "container_uri = 'us-docker.pkg.dev/vertex-ai/training/tf-gpu.2-4:latest'\n",
    "args = [\n",
    "    '--output_path=' + output_path, \n",
    "]\n",
    "\n",
    "machine_type = 'n1-standard-4'\n",
    "accelerator_type = 'NVIDIA_TESLA_T4'\n",
    "accelerator_count = 1\n",
    "\n",
    "job = vertex_ai.CustomJob.from_local_script(\n",
    "    display_name=job_name,\n",
    "    machine_type=machine_type,\n",
    "    accelerator_type=accelerator_type,\n",
    "    accelerator_count=accelerator_count,\n",
    "    script_path=file_path,\n",
    "    container_uri=container_uri,\n",
    "    args=args,\n",
    "    staging_bucket=base_output_dir\n",
    ")\n",
    "\n",
    "job.run(sync=False, \n",
    "#        service_account=VERTEX_SA,\n",
    "#        tensorboard=TENSORBOARD,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6504da19",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m75"
  },
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
